{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 04 — Phoneme Analysis\n",
    "\n",
    "This notebook analyzes how Whisper's output maps to Dothraki phonemes.\n",
    "We compare the IPA phonemes extracted from Whisper's transcription\n",
    "against the known Dothraki IPA ground truth.\n",
    "\n",
    "## Contents\n",
    "1. [Phonemization Pipeline](#1-phonemization) — How words become phonemes\n",
    "2. [Phoneme Distributions](#2-distributions) — Ground truth vs extracted\n",
    "3. [Phoneme Confusion](#3-confusion) — Which sounds get mixed up?\n",
    "4. [Articulatory Analysis](#4-articulatory) — Where in the mouth do errors happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "RESULTS_DIR = PROJECT_ROOT / 'data' / 'results'\n",
    "LEXICON_PATH = PROJECT_ROOT / 'data' / 'lexicon' / 'dothraki_lexicon.json'\n",
    "DIALOGUE_PATH = PROJECT_ROOT / 'data' / 'dialogue' / 'dothraki_dialogue.json'\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "eval_small = json.loads((RESULTS_DIR / 'batch_eval_small.json').read_text())\n",
    "lexicon = json.loads(LEXICON_PATH.read_text())\n",
    "dialogue = json.loads(DIALOGUE_PATH.read_text())\n",
    "\n",
    "print(f'Loaded: {eval_small[\"num_clips\"]} evaluated clips, {len(lexicon)} lexicon entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Phonemization Pipeline\n",
    "\n",
    "The phonemization step converts Whisper's text output into IPA phonemes.\n",
    "Since Whisper thinks it's hearing English (or other languages), we use\n",
    "gruut/espeak-ng to extract the IPA for whatever language was detected.\n",
    "\n",
    "```\n",
    "Whisper output (text) → Language detection → gruut/espeak-ng → IPA phonemes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.dothraki.phonemizer import phonemize_text, whisper_lang_to_gruut\n",
    "\n",
    "# Demonstrate the phonemization pipeline on a few examples\n",
    "results = eval_small['results']\n",
    "nonempty = [r for r in results if r.get('whisper_text', '').strip() and 'error' not in r]\n",
    "\n",
    "print(f'Phonemizing {min(8, len(nonempty))} sample transcriptions...\\n')\n",
    "print(f'{\"Whisper Output\":30s} {\"Detected Lang\":>12s}  {\"Extracted IPA\"}')\n",
    "print('-' * 80)\n",
    "\n",
    "for r in nonempty[:8]:\n",
    "    lang = whisper_lang_to_gruut(r['whisper_lang'])\n",
    "    phonemes = phonemize_text(r['whisper_text'][:50], lang=lang, whisper_lang=r['whisper_lang'])\n",
    "    ipa_str = ' '.join(ipa for _, ipa in phonemes if ipa)\n",
    "    print(f'{r[\"whisper_text\"][:30]:30s} {r[\"whisper_lang\"]:>12s}  {ipa_str[:40]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Phoneme Distributions\n",
    "\n",
    "Comparing the phoneme frequency distribution from:\n",
    "- **Ground truth:** The known Dothraki IPA transcriptions from the dialogue scripts\n",
    "- **Whisper-derived:** IPA extracted from Whisper's output via phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ground truth phonemes from dialogue IPA\n",
    "PHONEME_CHARS = set('abcdefghijklmnopqrstuvwxyzθðʃʒɾŋɣɔɛʔæɪʊɹɑə')\n",
    "\n",
    "gt_phonemes = []\n",
    "for r in results:\n",
    "    if 'error' in r:\n",
    "        continue\n",
    "    ipa = r.get('gt_ipa', '')\n",
    "    gt_phonemes.extend(c for c in ipa.lower() if c in PHONEME_CHARS)\n",
    "\n",
    "# Extract Whisper-derived phonemes\n",
    "whisper_phonemes = []\n",
    "for r in nonempty[:100]:  # Use first 100 for speed\n",
    "    lang = whisper_lang_to_gruut(r['whisper_lang'])\n",
    "    phonemes = phonemize_text(r['whisper_text'], lang=lang, whisper_lang=r['whisper_lang'])\n",
    "    for _, ipa in phonemes:\n",
    "        if ipa:\n",
    "            whisper_phonemes.extend(c for c in ipa.lower() if c in PHONEME_CHARS)\n",
    "\n",
    "gt_freq = Counter(gt_phonemes).most_common(25)\n",
    "whisper_freq = Counter(whisper_phonemes).most_common(25)\n",
    "\n",
    "print(f'Ground truth phoneme tokens: {len(gt_phonemes)}')\n",
    "print(f'Whisper-derived phoneme tokens: {len(whisper_phonemes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side phoneme frequency comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "if gt_freq:\n",
    "    labels_gt, counts_gt = zip(*gt_freq)\n",
    "    ax1.bar(range(len(labels_gt)), counts_gt, color='#4ecdc4', edgecolor='#1a1a2e', alpha=0.8)\n",
    "    ax1.set_xticks(range(len(labels_gt)))\n",
    "    ax1.set_xticklabels(labels_gt, fontsize=13)\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Ground Truth Dothraki Phonemes')\n",
    "\n",
    "if whisper_freq:\n",
    "    labels_w, counts_w = zip(*whisper_freq)\n",
    "    ax2.bar(range(len(labels_w)), counts_w, color='#ff6b6b', edgecolor='#1a1a2e', alpha=0.8)\n",
    "    ax2.set_xticks(range(len(labels_w)))\n",
    "    ax2.set_xticklabels(labels_w, fontsize=13)\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Whisper-Derived Phonemes (via English phonemizer)')\n",
    "\n",
    "fig.suptitle('Phoneme Frequency: Ground Truth vs Whisper Output', fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dothraki-specific phonemes: which are present in GT but rare/absent in Whisper output?\n",
    "gt_set = set(gt_phonemes)\n",
    "whisper_set = set(whisper_phonemes)\n",
    "\n",
    "gt_only = gt_set - whisper_set\n",
    "whisper_only = whisper_set - gt_set\n",
    "shared = gt_set & whisper_set\n",
    "\n",
    "print(f'Phonemes in ground truth only:    {sorted(gt_only)}')\n",
    "print(f'Phonemes in Whisper output only:  {sorted(whisper_only)}')\n",
    "print(f'Shared phonemes:                  {len(shared)}')\n",
    "print(f'\\nDothraki phonemes Whisper misses: These are the sounds Whisper cannot')\n",
    "print(f'recognize because they don\\'t exist in the language it thinks it\\'s hearing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Phoneme Confusion\n",
    "\n",
    "Analyzing which Dothraki phonemes get confused with which language phonemes.\n",
    "This is the core challenge: when Whisper hears /θ/ (Dothraki \"th\"),\n",
    "does it map it to English /θ/ (\"think\") or something else entirely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a co-occurrence matrix: for each evaluated clip,\n",
    "# compare GT phoneme distribution vs Whisper phoneme distribution\n",
    "\n",
    "# Aggregate phoneme proportions\n",
    "gt_counter = Counter(gt_phonemes)\n",
    "whisper_counter = Counter(whisper_phonemes)\n",
    "\n",
    "# Normalize to proportions\n",
    "all_phonemes_union = sorted(gt_set | whisper_set)\n",
    "gt_total = sum(gt_counter.values())\n",
    "whisper_total = sum(whisper_counter.values())\n",
    "\n",
    "gt_props = [gt_counter.get(p, 0) / gt_total for p in all_phonemes_union]\n",
    "whisper_props = [whisper_counter.get(p, 0) / whisper_total for p in all_phonemes_union]\n",
    "\n",
    "# Bar chart comparison\n",
    "x = np.arange(len(all_phonemes_union))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "bars1 = ax.bar(x - width/2, gt_props, width, label='Ground Truth (Dothraki)', color='#4ecdc4', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, whisper_props, width, label='Whisper-Derived', color='#ff6b6b', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Phoneme')\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title('Phoneme Proportion: Ground Truth vs Whisper-Derived')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_phonemes_union, fontsize=12)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find biggest divergences\n",
    "divergences = [(p, gt_counter.get(p, 0)/gt_total - whisper_counter.get(p, 0)/whisper_total)\n",
    "               for p in all_phonemes_union]\n",
    "divergences.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print('\\nBiggest phoneme divergences (GT proportion - Whisper proportion):')\n",
    "for p, diff in divergences[:10]:\n",
    "    direction = 'under-represented in Whisper' if diff > 0 else 'over-represented in Whisper'\n",
    "    print(f'  /{p}/: {diff:+.4f} ({direction})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Articulatory Analysis\n",
    "\n",
    "Dothraki phonemes categorized by articulatory features.\n",
    "This helps understand which *types* of sounds are hardest for Whisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize Dothraki phonemes by manner of articulation\n",
    "MANNER_CATEGORIES = {\n",
    "    'Plosives': list('pttkdgkqbg'),\n",
    "    'Fricatives': list('fvsz') + ['θ', 'ð', 'ʃ', 'ʒ', 'x', 'ɣ', 'h'],\n",
    "    'Nasals': list('mn') + ['ŋ'],\n",
    "    'Approximants': list('wjlr') + ['ɾ', 'ɹ'],\n",
    "    'Vowels': list('aeiou') + ['ɔ', 'ɛ', 'æ', 'ɪ', 'ʊ', 'ɑ', 'ə'],\n",
    "}\n",
    "\n",
    "# Count GT phonemes by category\n",
    "gt_by_manner = {}\n",
    "whisper_by_manner = {}\n",
    "for category, phones in MANNER_CATEGORIES.items():\n",
    "    gt_by_manner[category] = sum(gt_counter.get(p, 0) for p in phones)\n",
    "    whisper_by_manner[category] = sum(whisper_counter.get(p, 0) for p in phones)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "categories = list(MANNER_CATEGORIES.keys())\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "gt_vals = [gt_by_manner[c] / gt_total * 100 for c in categories]\n",
    "w_vals = [whisper_by_manner[c] / whisper_total * 100 for c in categories]\n",
    "\n",
    "ax.bar(x - width/2, gt_vals, width, label='Ground Truth', color='#4ecdc4', alpha=0.8)\n",
    "ax.bar(x + width/2, w_vals, width, label='Whisper-Derived', color='#ff6b6b', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Manner of Articulation')\n",
    "ax.set_ylabel('Percentage of Total Phonemes')\n",
    "ax.set_title('Phoneme Category Distribution: GT vs Whisper')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nInsight: Differences in category distribution reveal systematic biases.')\n",
    "print('E.g., if Whisper over-represents vowels, it may be hallucinating')\n",
    "print('vowel-heavy English words to fill gaps in Dothraki consonant clusters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dothraki phoneme inventory from the lexicon\n",
    "all_lex_ipa = ''.join(e['ipa'] for e in lexicon if e.get('ipa'))\n",
    "lex_phonemes = [c for c in all_lex_ipa.lower() if c in PHONEME_CHARS]\n",
    "lex_unique = sorted(set(lex_phonemes))\n",
    "\n",
    "print('Dothraki Phoneme Inventory (from lexicon):')\n",
    "print(f'  Total unique: {len(lex_unique)}')\n",
    "\n",
    "consonants = [p for p in lex_unique if p not in 'aeiouɔɛæɪʊɑə']\n",
    "vowels = [p for p in lex_unique if p in 'aeiouɔɛæɪʊɑə']\n",
    "print(f'  Consonants ({len(consonants)}): {\" \".join(consonants)}')\n",
    "print(f'  Vowels ({len(vowels)}): {\" \".join(vowels)}')\n",
    "\n",
    "# Which Dothraki sounds don't exist in English?\n",
    "english_phonemes = set('pbmfvθðtdnszʃʒlɹjkgŋhwaeɪɛæəɑɔʊu')\n",
    "dothraki_non_english = set(lex_unique) - english_phonemes\n",
    "print(f'\\n  Non-English Dothraki sounds: {sorted(dothraki_non_english)}')\n",
    "print(f'  These are the hardest for Whisper to handle since it expects English.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}